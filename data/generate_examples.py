"""Generate example sentences for Book 1 words using Gemini API."""
import json
import time
import requests

GEMINI_API_KEY = "AIzaSyAGf0KxjRX7aiqBJAv_E6hCoqU9fT2DVgg"
GEMINI_URL = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?key={GEMINI_API_KEY}"
BATCH_SIZE = 20

def generate_batch(words_batch):
    """Send a batch of words to Gemini and get example sentences."""
    word_list = "\n".join(
        f"{i+1}. {w['english']} ({w['pos']}) - {w['korean']}"
        for i, w in enumerate(words_batch)
    )

    prompt = f"""For each English word below, create ONE natural example sentence.
Rules:
- Suitable for Korean middle school students (simple, clear)
- Use the word in a way that makes its meaning obvious from context
- Keep sentences under 15 words
- Return ONLY numbered lines in format: 1. word - Example sentence.

Words:
{word_list}"""

    body = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.7,
            "maxOutputTokens": 1024,
        },
    }

    resp = requests.post(GEMINI_URL, json=body, timeout=30)
    resp.raise_for_status()
    data = resp.json()

    text = data["candidates"][0]["content"]["parts"][0]["text"]
    return text


def parse_response(text, words_batch):
    """Parse Gemini response into word-sentence pairs."""
    results = []
    lines = [l.strip() for l in text.strip().split("\n") if l.strip()]

    for i, word in enumerate(words_batch):
        sentence = ""
        # Try to match by number prefix
        for line in lines:
            if line.startswith(f"{i+1}."):
                # Remove "1. word - " prefix
                parts = line.split(" - ", 1)
                if len(parts) >= 2:
                    sentence = parts[-1].strip()
                else:
                    sentence = line.split(".", 1)[-1].strip()
                break
        results.append({
            "english": word["english"],
            "korean": word["korean"],
            "lesson": word["lesson"],
            "pos": word["pos"],
            "example": sentence,
        })
    return results


def main():
    with open("D:/wordtest/data/book1_words.json", "r", encoding="utf-8") as f:
        words = json.load(f)

    print(f"Total words: {len(words)}")
    all_results = []
    total_batches = (len(words) + BATCH_SIZE - 1) // BATCH_SIZE

    for i in range(0, len(words), BATCH_SIZE):
        batch = words[i : i + BATCH_SIZE]
        batch_num = i // BATCH_SIZE + 1
        print(f"  Batch {batch_num}/{total_batches} ({len(batch)} words)...", end=" ", flush=True)

        try:
            raw = generate_batch(batch)
            parsed = parse_response(raw, batch)
            all_results.extend(parsed)
            success = sum(1 for r in parsed if r["example"])
            print(f"OK ({success}/{len(batch)})")
        except Exception as e:
            print(f"ERROR: {e}")
            # Add empty results for failed batch
            for w in batch:
                all_results.append({
                    "english": w["english"],
                    "korean": w["korean"],
                    "lesson": w["lesson"],
                    "pos": w["pos"],
                    "example": "",
                })

        # Rate limit: 15 RPM for free tier = 4 sec between requests
        if i + BATCH_SIZE < len(words):
            time.sleep(4)

    # Save as markdown
    md_lines = [
        "# Power Voca 5000-01 - Example Sentences",
        "",
        f"> Generated by Gemini 2.0 Flash-Lite | {len(all_results)} words",
        "",
    ]

    current_lesson = ""
    for r in all_results:
        if r["lesson"] != current_lesson:
            current_lesson = r["lesson"]
            md_lines.append(f"## {current_lesson}")
            md_lines.append("")
            md_lines.append("| English | Korean | POS | Example |")
            md_lines.append("|---------|--------|-----|---------|")

        ex = r["example"] if r["example"] else "(failed)"
        md_lines.append(f"| {r['english']} | {r['korean']} | {r['pos']} | {ex} |")

    md_lines.append("")

    with open("D:/wordtest/data/book1_examples.md", "w", encoding="utf-8") as f:
        f.write("\n".join(md_lines))

    # Stats
    success = sum(1 for r in all_results if r["example"])
    print(f"\nDone! {success}/{len(all_results)} examples generated")
    print(f"Saved to: data/book1_examples.md")


if __name__ == "__main__":
    main()
